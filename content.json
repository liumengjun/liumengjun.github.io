[{"title":"分布式数据计算引擎研习","date":"2021-03-18T13:10:35.000Z","path":"2021/03/18/distributed-computation.html","text":"distributed computing frameworksspark, impala, bigquery, dask .etc Big Concept1, 经典MapReduce(Calculate Word Count by MapReduce) MapReduce采用“分而治之”策略。MapReduce将复杂的、运行于大规模集群上的并行计算过程高度地抽象到了两个函数：Map和Reduce。一个存储在分布式文件系统中的大规模数据集，会被切分成许多独立的分片（split），这些分片可以被多个Map任务并行处理。通过Reduce最终把各个分片任务中间结果合并成一个结果。 2, DAG(Directed Acyclic Graph)有向无环图(Spark DAG Demo) RDD算子构建了RDD之间的关系，整个计算过程形成了一个由RDD和关系构成的DAG。点就是RDD（或者stage）, 线就是RDD算子（或者宽依赖算子） 1234我们使用 spark-submit 提交的就是一个 application， 一个 application 可以有很多job。对 RDD 进行 action操作时，就会产生一个Job。每一个Job 又会根据 shuffle 操作，分为多个stage。一个stage会根据RDD的分区数，分为多个task。 3, MLST (Multi-Level Service Tree)(An example of Dremel Service-Tree) 根服务器收到此查询时，首先要做的是将查询转换为可以由下一级别的服务树处理的形式。它确定表T的所有分片，然后简化查询。在这里，R11，R12，…R1n是发送到服务树的第1级的Mixer 1,…,n的查询结果。R1i = SELECT A, COUNT(B) AS c FROM T1i GROUP BY A下一步Mixer修改传入的查询，以便它们可以将其传递给Leaf节点。叶子节点接收自定义查询并从Colossus(数据存储层)分片读取数据。Lead节点读取查询中提到的列或字段的数据。当叶节点扫描分片时，它并行地浏览打开的列文件，一次一行。 spark vs impalaImpala查询器将所有内容缓存在内存中，而Spark将需要时间来提取此数据以执行查询计划。 shuffle实现方式, Spark在stage边界将临时文件写入磁盘，然而Impala尝试将所有内容保留在内存中。 Spark可以从丢失执行程序中恢复并通过重新计算丢失的块继续运行, Impala在单个impalad守护程序崩溃后将使整个查询失败。 工作分配机制不同 – Spark(DAG)将编译生成后的整个阶段代码发送给workers，Impala(MLST)只传递声明式查询片段。 “查询优化技术（查询矢量化，动态分区修剪，基于成本的优化）-平分秋色，提升点也差不多。” Dask Example(Dask Task Graph Example) 积分方式计算ACBD区域面积 sum(y0(x) - y3(x) for x in x_range) 1234567891011121314151617181920n = 16delta_x = 1 / nx_range = [i / n for i in range(n)]def y0(x): \"\"\"y0 = sqrt(1-x^2)\"\"\" import math return delta_x * math.sqrt(1 - x * x)def y3(x): \"\"\"y3 = 1 - x\"\"\" return delta_x * (1 - x)a_quarter_circle_y = client.map(y0, x_range)a_triangle_y = client.map(y3, x_range)a_target_s = client.map(operator.sub, a_quarter_circle_y, a_triangle_y)a_target = client.submit(sum, a_target_s)# a_target.result()# 0.28081325945693536 dask vs sparkSpark和Dask都用有向无环图表示计算。但是这些图的粒度不同。 在Spark RDD上执行的一项操作可能会将一个节点（例如Map和Filter）添加到图形中。这些是传达含义的高级操作，最终将变成许多要在单个工人上执行的小任务。这个小任务状态仅在Spark调度程序内部可用。（Spark stage 是一个物理执行单位。stage 是一组并行任务 - 每个分区一个任务。） Dask跳过了这种高级表示，而直接进入了许多小任务阶段。这样，对Dask集合进行一次映射操作将立即生成并可能将数千个微小任务添加到Dask图中。 基础图规模的这种差异影响着可以进行的分析和优化的种类，也影响了用户暴露给用户的普遍性。 Dask无法执行Spark进行的某些优化，因为Dask调度程序没有自上而下执行的计算的图。但是，Dask能够轻松代表更复杂的算法，并将这些算法的创建向普通用户公开。 参考链接 https://data-flair.training/blogs/dag-in-apache-spark/ https://storage.googleapis.com/pub-tools-public-publication-data/pdf/36632.pdf https://panoply.io/data-warehouse-guide/bigquery-architecture/ https://docs.dask.org/en/latest/spark.html https://www.jianshu.com/p/8c7e0f5ff326 https://waltyou.github.io/Spark-Tuning-Practice/ https://waltyou.github.io/Mastering-Apache-Spark-Core-7-Services-DAGScheduler/ https://stackoverflow.com/questions/58598727/impala-vs-spark-performance-for-ad-hoc-queries","categories":[{"name":"大数据","slug":"大数据","permalink":"https://liumengjun.github.io/categories/大数据/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://liumengjun.github.io/tags/数据库/"},{"name":"大数据","slug":"大数据","permalink":"https://liumengjun.github.io/tags/大数据/"}]},{"title":"漫谈数据存储发展","date":"2021-01-26T13:31:17.000Z","path":"2021/01/26/data-store-trend.html","text":"用发展的眼光看问题（但是如何实践还是很难的） 1. 概览数据存储方式变化 文本文件(csv, xml, json) 二进制文件(*.dat, excel)(RCFile, Avro, parquet, orc) sql rdb no sql redis &lt;key, value&gt; mongo (partition, shard) big table {HBase} （row, column family, time）, slice, tablet es (cluster 、 node 、 shard{ Lucene }) 图数据库 {Neo4J} (node - relation) OceanBase？ TiDB，CockroachDB 1.1 RDBMS vs NoSQL 1.1.1 RDBMSRDBMS特点 高度组织化结构化数据 结构化查询语言（SQL） (SQL) 数据和关系都存储在单独的表中。 数据操纵语言，数据定义语言 严格的一致性 基础事务ACID 过一下RDBMS有哪些 ms access db FoxPro SQL Server DB2 Oracle MySQL (MariaDB, Percona) PostgreSQL sqlite3 H2 hsqldb 1.1.2 NoSQL(Not Only)NoSQL特点 代表着不仅仅是SQL 没有声明性查询语言 没有预定义的模式 键 - 值对存储，列存储，文档存储，图形数据库 最终一致性，而非ACID属性 非结构化和不可预知的数据 高性能，高可用性和可伸缩性 NoSQL 数据库分类 类型 部分代表 特点 列存储 Hbase，Cassandra，Hypertable，ClickHouse 顾名思义，是按列存储数据的。最大的特点是方便存储结构化和半结构化数据，方便做数据压缩，对针对某一列或者某几列的查询有非常大的IO优势。 文档存储 MongoDB，CouchDB 文档存储一般用类似json的格式存储，存储的内容是文档型的。这样也就有机会对某些字段建立索引，实现关系数据库的某些功能。 key-value存储 Tokyo Cabinet / Tyrant，Berkeley DB，MemcacheDB，Redis 可以通过key快速查询到其value。一般来说，存储不管value的格式，照单全收。（Redis包含了其他功能） 图存储 Neo4J，FlockDB 图形关系的最佳存储。使用传统关系数据库来解决的话性能低下，而且设计使用不方便。 对象存储 db4o，Versant 通过类似面向对象语言的语法操作数据库，通过对象的方式存取数据。 xml数据库 Berkeley DB XML，BaseX 高效的存储XML数据，并支持XML的内部查询语法，比如XQuery,Xpath。 NoSQL的优点/缺点优点: 高可扩展性 分布式计算 低成本 架构的灵活性，半结构化数据 没有复杂的关系 缺点: 没有标准化 有限的查询功能（到目前为止） 最终一致是不直观的程序 1.2 NewSQLNewSQL 是一种新方式关系数据库，意在整合 RDBMS 所提供的ACID事务特性（即原子性、一致性、隔离性和可持久性），以及 NoSQL 提供的横向可扩展性。 比如，MyRocks，TiDB，参考F1/Spanner。 (了解不多，请大家一起研究) 2. 数据如何存储的2.1 行模式 vs 列模式 2.2 存储引擎（MySQL发扬的概念）以及索引组织方式Memory MyISAM(My索引顺序存取方法)(最初是IBM公司发展起来的一个文件系统) InnoDB Merge tokuDB MyRocks 索引组织方式Hash RTree Fractal树(分形树) B+Tree Log Structured Merge Trees(LSM) {MemTable, SSTable(Sorted String Table)} (From BigTable) @B+Tree结构图 @LSM Tree 结构图 2.2 分布式读写分类 mongo分片集合 elastic节点分区和复制（elastic_nodes_0204） CAP定理（CAP theorem）在计算机科学中, CAP定理（CAP theorem）, 又被称作 布鲁尔定理（Brewer’s theorem）, 它指出对于一个分布式计算系统来说，不可能同时满足以下三点: 一致性(Consistency) (所有节点在同一时间具有相同的数据) 可用性(Availability) (保证每个请求不管成功或者失败都有响应) 分隔容忍(Partition tolerance) (系统中任意信息的丢失或失败不会影响系统的继续运作) CAP理论的核心是：一个分布式系统不可能同时很好的满足一致性，可用性和分区容错性这三个需求，最多只能同时较好的满足两个。 因此，根据 CAP 原理将 NoSQL 数据库分成了满足 CA 原则、满足 CP 原则和满足 AP 原则三 大类： CA - 单点集群，满足一致性，可用性的系统，通常在可扩展性上不太强大。 CP - 满足一致性，分区容忍性的系统，通常性能不是特别高。 AP - 满足可用性，分区容忍性的系统，通常可能对一致性要求低一些。 分布式算法 Paxos算法: 各副本竞争提议权，然后让议案在各副本间达成一致 Raft算法: 先选举出leader，leader完全负责replicated log的管理。 一致性hash算法(归位分布式算法有些牵强): 以前点映射改为区段映射，使得数据节点变更后其他数据节点变动尽可能小 EPaxos（Egalitarian Paxos） NOTE: 分布式部署一般不保证事务，这是NEWSQL要挑战的难点。Google的Spanner/F1提出了一种TrueTime API，使得事务序列化满足外部一致性。 参考:https://www.cnblogs.com/hdc520/p/13718470.html https://www.runoob.com/mongodb/nosql.html http://dblab.xmu.edu.cn/post/google-bigtable/ https://cloud.tencent.com/developer/article/1131036 https://segmentfault.com/a/1190000009707788 https://static.googleusercontent.com/media/research.google.com/zh-CN//archive/bigtable-osdi06.pdf http://static.googleusercontent.com/media/research.google.com/en//archive/spanner-osdi2012.pdf http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/41344.pdf","categories":[{"name":"大数据","slug":"大数据","permalink":"https://liumengjun.github.io/categories/大数据/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://liumengjun.github.io/tags/数据库/"},{"name":"大数据","slug":"大数据","permalink":"https://liumengjun.github.io/tags/大数据/"}]},{"title":"Kafka入门","date":"2021-01-25T14:53:43.000Z","path":"2021/01/25/kafka-intro.html","text":"web sites home: http://kafka.apache.org/ wiki: https://cwiki.apache.org/confluence/display/KAFKA/Index 生态: https://cwiki.apache.org/confluence/display/KAFKA/Ecosystem wikipedia 介绍Kafka from领英，2011年初开源，并于2012年10月23日由Apache Incubator孵化出站。2014年11月，几个曾在领英为Kafka工作的工程师，创建了confluent.io新公司。根据2014年Quora的帖子，Jay Kreps似乎已经将它以作家弗朗茨·卡夫卡命名，它是“一个用于优化写作的系统”。 different with MessageQueue common mq: RabbitMQ, Redis, ActiveMQ, zeroMQ, rocketMQ，数据库？应用服务器间消息传递 kafka: 主要用于处理活跃的流式数据,大数据量的数据处理上. get started 下载安装, 可以配置KAFKA_HOME和PATH 12export KAFKA_HOME=\"/data/tools/kafka\"export PATH=\"$PATH:$KAFKA_HOME/bin\" 单机配置: 另选zookeeper port, 一些工作目录 /tmp/ -&gt; 正常目录(注意磁盘和内存大小？daily-disk-clean.sh) zookeeper config(zookeeper.properties) 12dataDir=/data/appdata/kafka/zookeeperclientPort=32181 kafka server config(server.properties) 1234zookeeper.connect=localhost:32181log.dirs=/data/appdata/kafka/kafka-logslog.retention.hours=90log.retention.bytes=61073741824 启动 zookeeper &amp; kafka，包装启动脚本，放到$HOME/bin kafka_zk_start 123#!/bin/bashcd $KAFKA_HOMEnohup bin/zookeeper-server-start.sh config/zookeeper.properties &amp; kafka_server_start 123#!/bin/bashcd $KAFKA_HOMEnohup bin/kafka-server-start.sh config/server.properties &amp; 创建topic create 12# createkafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic test list 1kafka-topics.sh --list --bootstrap-server localhost:9092 --bootstrap-server 指定kafka server，也可用--zookeeper 启动producer发送信息 1kafka-console-producer.sh --bootstrap-server localhost:9092 --topic test 不创建topic，直接指定topic发消息，也会自动创建。advoracle/cli/tool/userlog2kafka.py 启动consumer接收消息 1kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning 可以看到正在发送的消息，也可看到之前发送的消息 去掉--from-beginning, 只能看到正在发送的消息 Kafka Web Managerhttps://github.com/yahoo/CMAK scala项目, 效果: http://localhost:9000/ 客户端详见: https://cwiki.apache.org/confluence/display/KAFKA/Clients python: confluent-kafka others 集群部署 Connect组件导入导出迁移数据 Kafka Stream, 致力于流式计算框架，like flink。所以还有个产品叫ksqlDB","categories":[{"name":"数据流处理","slug":"数据流处理","permalink":"https://liumengjun.github.io/categories/数据流处理/"}],"tags":[{"name":"java","slug":"java","permalink":"https://liumengjun.github.io/tags/java/"},{"name":"消息队列","slug":"消息队列","permalink":"https://liumengjun.github.io/tags/消息队列/"},{"name":"数据流处理","slug":"数据流处理","permalink":"https://liumengjun.github.io/tags/数据流处理/"}]},{"title":"JPA query 的几种写法","date":"2019-05-08T13:57:32.000Z","path":"2019/05/08/jpa-query-demos.html","text":"1. jpqlJPQL is hql? jpa 是javaee的一部分规范，spring data jpa 采用hibernate实现，eclipse也有实现JPA，等等 https://zh.wikipedia.org/wiki/Java%E6%8C%81%E4%B9%85%E5%8C%96API https://jcp.org/aboutJava/communityprocess/final/jsr338/index.html interfaces 命名 findXxx findBy count page 注解中写法 @query (nativeQuery=false) select * from Entity select e from Entity e select e.* from Entity e from Entity select col1, col2, col3 from Entity // List&lt;Object[]&gt; select new ai.advance.your.package.Pojo(col1, col2, col3) from Entity select new map(… // 这种方式很傻，key为”0”,”1”.etc（??col as keyName） 构造criteria query @query (nativeQuery=false)是静态的，criteria可以用程序动态组装查询语句 criteria: CriteriaBuilder + CriteriaQuery + Expression + Predicate =&gt; TypedQuery 123final Root&lt;?&gt; root = query.from(Entity.class);query.where(this.buildPredicates(root, builder, params...));return lem.createQuery(query).getResultList(); Specification 类似 Example 很懒 Join 比较复杂, 需要定义Entity时就指明关联关系 result type select(root) Pojo(field1, field2) + Root, builder.createQuery(Pojo.class) + multiselect(field1, field2)Root仍然是Entity，用于组装Selection，Pojo为结果类型 builder.construct(Pojo.class, field1, field2) 同上 Tuple 作为结果类型 没有Pojo类，结果为Object[] 2. native sql@query (nativeQuery=true) 普通的sql，大家好像偏爱这种方式 方便join语句 方便各种聚合查询 createNativeQuery带参数时要防止sql注入 程序组装sql，更灵活的方式写sql 注意模糊查询参数设置 123sql += \"col like :key\";...query.setParameter(key, \"%\" + value + \"%\"); 结果类型和result transformernative query时可显示指定结果类型固定（即使select个别字段）, 有时可以借助ResultTransformer以返回更多样的结果类型 Object[]no resultType no transformer Map&lt;String, Object&gt;map transformer Pojo createNativeQuery(Pojo.class) Transformers.aliasToBean(Pojo.class). sql中下划线col需要显示指定别名和Pojo中field名称相同 List，Transformers.TO_LIST, bad idea result transformer 例子 12345String sql = \"select col1, col2, col3 from t_entity\";Query query = em.createNativeQuery(sql); // no resultClass// Query 接口是 spring-data-jpa 的接口，而 org.hibernate.SQLQuery 接口是 hibenate 的接口，这里的做法就是先转成 hibenate 的查询接口对象，然后设置结果转换器query.unwrap(org.hibernate.SQLQuery.class).setResultTransformer(Transformers.ALIAS_TO_ENTITY_MAP);return query.getResultList(); // List&lt;Map&lt;String, Object&gt;&gt;, key为列名，含有下划线 criteria 风格的 TypedQuery 生成的sql语句alias是col_m_n_之类的，不适用ALIAS_TO_ENTITY_MAP，aliasToBean。 query.unwrap 参数为org.hibernate.SQLQuery，而不是org.hibernate.Query。TypedQuery不能unwrap为org.hibernate.SQLQuery，即使unwrap成org.hibernate.Query，也得不到任何结果。 ResultTransformer接口 3. 分页 老老实实limit offset, size JPA page小优化: 如果返回条数n小于size，就可以推测总条数为offset+n，否则，还需要再查询一次总条数 确定数据量小，比如&lt;1000，可以选择在应用服务器里分页，甚至都丢给web端让web端分页 数据量特大，where id &gt; last_page_max_id limit size，这样可以不管总条数是多少，如果where查询恰好为索引，总条数计算快，否则慢的不可想象 n. 原则 具体类型对宽泛的类型更好 使用索引 select 必要的字段 大量数据时分批","categories":[{"name":"服务端","slug":"服务端","permalink":"https://liumengjun.github.io/categories/服务端/"}],"tags":[{"name":"java","slug":"java","permalink":"https://liumengjun.github.io/tags/java/"},{"name":"jpa","slug":"jpa","permalink":"https://liumengjun.github.io/tags/jpa/"}]},{"title":"java11 var 关键字和 cli 方式执行","date":"2019-03-29T13:47:06.000Z","path":"2019/03/29/java11-var-shebang-feature.html","text":"java11 在语法上支持动态类型推断，还支持在命令行运行源码。其实var关键字在java10已经支持了，而且从java9开始就添加了jshell命令等，不过9和10都已经夭折了，而且现在java11都更新过一个版本了，我们大大方方的讨论java11吧。 动态类型推断，这个术语可能不严谨，openjdk网站上描述是Local-Variable Type Inference(本地变量类型推断)，参考 JEP 286。 在命令行运行源码，不是指jshell，而是Launch Single-File Source-Code Programs(启动单个源码程序)，java命令直接启动源码文件，还有shebang特性，参考 JEP 330。 看个简单例子：创建Hello.java文件，内容如下12345678910111213import java.util.ArrayList;public class Hello &#123; public static void main(String[] args) &#123; var list = new ArrayList&lt;&gt;(); var hi = \"hello world\"; var bool = true; var i = 1; list.add(hi); list.add(bool); list.add(i+i); System.out.println(list); &#125;&#125; 可以看到代码中使用了var关键字，即使用了动态类型推断特性。然后，在命令行中执行java Hello.java命令，输出[hello world, true, 2]。 注意：如果你的系统中安装了多个java版本，请确保java11为当前默认的java版本。比如，也安装了java8，而且平时默认是java8，需要临时改一下：在命令行中设置JAVA_HOME为jdk11的安装目录，然后把新JAVA_HOME/bin路径放到当前PATH的环境变量的最前面，这样就可以了。 下面看一看Shebang特性：把Hello.java复制一份为Hello，cp Hello.java Hello，然后在Hello的文件头添加一行内容#!/usr/bin/java --source 11(注意，不要直接修改Hello.java文件)。此时文件内容形如： 123456#!/usr/bin/java --source 11import java.util.ArrayList;public class Hello &#123; public static void main(String[] args) &#123; var list = new ArrayList&lt;&gt;();... ... 把Hello设置为可执行文件chmod +x Hello，然后执行1./Hello 可以看到命令正常运行，输出[hello world, true, 2]。 参考 http://openjdk.java.net/jeps/286 http://openjdk.java.net/jeps/330 https://stackoverflow.com/questions/52530470/java-11-executing-source-file-via-shebang-is-not-working","categories":[{"name":"程序语言","slug":"程序语言","permalink":"https://liumengjun.github.io/categories/程序语言/"}],"tags":[{"name":"java","slug":"java","permalink":"https://liumengjun.github.io/tags/java/"}]},{"title":"构建 puppeteer docker 镜像","date":"2019-03-16T12:17:00.000Z","path":"2019/03/16/node-puppeteer-docker.html","text":"有时候需要在服务端生成PDF，可是在服务端生成的PDF不如浏览器中看到的页面美观，就想到了浏览器headless模式，在服务端访问前端，然后以PDF格式打印网页。前端大神安利了puppeteer，确实很不错，还支持定制页眉页脚。再者服务端程序是使用docker管理的，所以需要创建含有puppeteer的docker镜像。 先看Dockerfile123456789101112131415161718192021222324252627# 基于`alpine`版本的`node`10FROM node:10.15.2-alpine# 安装 Chromium (72)。从 alpine/v3.9 版本库中下载RUN apk update &amp;&amp; apk upgrade &amp;&amp; \\ echo @v3.9 http://dl-cdn.alpinelinux.org/alpine/v3.9/community &gt;&gt; /etc/apk/repositories &amp;&amp; \\ echo @v3.9 http://dl-cdn.alpinelinux.org/alpine/v3.9/main &gt;&gt; /etc/apk/repositories &amp;&amp; \\ apk add --no-cache \\ freetype@v3.9 \\ chromium@v3.9 \\ harfbuzz@v3.9 \\ nss@v3.9# 安装 Puppeteer 时不让它自动下载 ChromiumENV PUPPETEER_SKIP_CHROMIUM_DOWNLOAD true# 选择 Chromium 72 对应的 Puppeteer 版本RUN yarn add puppeteer@1.11.0# 添加用户RUN addgroup -S pptruser &amp;&amp; adduser -S -g pptruser pptruser \\ &amp;&amp; mkdir -p /home/pptruser/Downloads \\ &amp;&amp; chown -R pptruser:pptruser /home/pptruser# 添加 cjk 字体以支持中文COPY NotoSansCJK-Regular.ttc /usr/share/fonts/TTFUSER pptruser Dockerfile部分说明 选择alpine版，是因为已有alpine版的java镜像。其实docker不支持合并镜像，还需要基于原java镜像再安装Puppeteer组成新的镜像 没有选择edge版仓库, edge是在开发中的, 有不确定性 已有java镜像alpine版本是v3.7, 有些工具包和此次版本不兼容，需要安装v3.9的freetype等 字体选择开源字体，防止被告 构建 docker image1docker build -t node-puppeteer:puppeteer1_11-node10-alpine . 下载该镜像 执行example12345# 当你执行时，最好使用`--volume`选项，方便取出后面生成的文件docker run -it --rm node-puppeteer:puppeteer1_11-node10-alpine shcd /tmpvi example.js # 内容如下node example.js # 得到 example.png example.js文件内容（此处以生成图片快照为例，若要生成PDF，请参考puppeteer文档）: 1234567891011const puppeteer = require('puppeteer');(async () =&gt; &#123; const browser = await puppeteer.launch(&#123; executablePath: '/usr/bin/chromium-browser', args: ['--no-sandbox', '--disable-setuid-sandbox'], &#125;); const page = await browser.newPage(); await page.goto('https://www.baidu.com'); await page.screenshot(&#123;path: 'example.png'&#125;); await browser.close();&#125;)(); 参考 https://github.com/GoogleChrome/puppeteer https://github.com/GoogleChrome/puppeteer/blob/master/docs/troubleshooting.md https://github.com/GoogleChrome/puppeteer/issues/1825 https://www.google.com/get/noto/ 开源字体 https://gitee.com/liumengjun/config-files/tree/master/nodejs/puppeteer-docker 源码","categories":[{"name":"服务端","slug":"服务端","permalink":"https://liumengjun.github.io/categories/服务端/"}],"tags":[{"name":"puppeteer","slug":"puppeteer","permalink":"https://liumengjun.github.io/tags/puppeteer/"},{"name":"node","slug":"node","permalink":"https://liumengjun.github.io/tags/node/"},{"name":"docker","slug":"docker","permalink":"https://liumengjun.github.io/tags/docker/"},{"name":"headless","slug":"headless","permalink":"https://liumengjun.github.io/tags/headless/"}]},{"title":"git stash clear 后恢复代码","date":"2019-01-15T13:32:21.000Z","path":"2019/01/15/recover-after-git-stash-clear.html","text":"使用git stash隐藏工作区内修改但未提交的代码，git stash list查看stash的历史记录，git stash clear清除所有的stash栈。 有时候可能不小心git stash clear掉了所有的记录，可是那些代码还有用。哎呀，杯具了，白写了！其实不用慌，可用下面的方法找回： 1git fsck --no-reflogs 2&gt;&amp;1 | awk '/dangling commit/ &#123;print $3&#125;' | xargs git show --stat 上述\b命令得到了所有dangling commit，其描述，以及修改的文件列表。观察一下，stash记录描述以WIP开头（work in progress缩写，进行中的工作），结合修改文件列表就能找到那个commit了。 然后执行git cherry-pick或者git stash apply命令就可以恢复了，参数是那个commit id。 解析： git fsck找出\b所有dangling的对象，也可以不加--no-reflogs参数。2&gt;&amp;1为了隐藏烦人的错误输出，可不加。 awk过滤\bcommit类型，并输出commit id值 xargs git show --stat对所有commit_id执行git show --stat命令","categories":[{"name":"代码管理","slug":"代码管理","permalink":"https://liumengjun.github.io/categories/代码管理/"}],"tags":[{"name":"git","slug":"git","permalink":"https://liumengjun.github.io/tags/git/"}]},{"title":"spring-cloud zone, 类似 dubbo group 功能","date":"2018-12-21T12:58:35.000Z","path":"2018/12/21/spring-cloud-zone-usage.html","text":"spring-cloud zone 本地开发使用 当我们使用spring-cloud微服务框架时(netflix eureka组合)，有很多微服务程序。开发时，本地启动eureka并注册所有微服务，成本太高。直接使用公共开发环境的eureka，确实省事。比如有A, B, C三个服务，A没有变化，B有修改，C有修改并调用B，此时本地不用启动A，只启动B和C就可以。不过不注意又有个问题，C调用B时，有时候调用公共环境上B服务，甚至其他开发者启动的B服务。dubbo有group配置给服务分组解决此问题；对于spring-cloud，此时需要配置zone: 12eureka.instance.metadataMap.zone: YOUR-NAMEeureka.client.preferSameZoneEureka: true 本地各个服务都配置zone且相同，各个开发者的zone不同，公共环境默认是defaultZone。然后，C调用B时，就不再混乱了，只调用本地的。(A服务则访问其他zone的) 刚接触spring-cloud时，不知道怎么解决这个问题，baidu或google搜spring-cloud中group功能也没有好答案。自己动手吧，写了个client继承LoadBalancerFeignClient，用@Configuration机制配置了下，忙活半天多，可以了。转念一想，不对啊，这个功能spring-cloud应该有啊，看看文档去吧。果不其然，确实有。犯了个错误：不看文档就瞎弄。使用xxx库或工具时，先看看xxx的官方文档，很有用！ 参考 https://cloud.spring.io/spring-cloud-netflix/spring-cloud-netflix.html#_zones","categories":[{"name":"框架","slug":"框架","permalink":"https://liumengjun.github.io/categories/框架/"}],"tags":[{"name":"java","slug":"java","permalink":"https://liumengjun.github.io/tags/java/"},{"name":"spring-cloud","slug":"spring-cloud","permalink":"https://liumengjun.github.io/tags/spring-cloud/"},{"name":"spring","slug":"spring","permalink":"https://liumengjun.github.io/tags/spring/"}]},{"title":"git clone/checkout 指定文件/目录","date":"2018-09-24T15:31:17.000Z","path":"2018/09/24/git-sparse-checkout.html","text":"对比svn，svn可以更新或下载特定目录(甚至精确控制每个目录权限)，可是git不可以吗？在Git1.7.0以前，这无法实现，但是幸运的是在Git1.7.0以后加入了Sparse Checkout（直译为：稀疏检出）模式，这使得Check Out指定文件或者目录成为可能。操作如下： 对于已有项目12345678910# 使能Sparse Checkout(稀疏检出)git config core.sparsecheckout true# 编辑'.git/info/sparse-checkout'，规则类似gitignore。比如echo '/srcreadme.md' &gt; .git/info/sparse-checkout# 只保留根目录下/src目录和readme.md文件git checkout# ls，就可以看到\b内容已经变了，只有src和readme.md两项 对于新项目1234567git init newdir &amp;&amp; cd newdir# 使能Sparse Checkout(稀疏检出)git config core.sparsecheckout true# 编辑'.git/info/sparse-checkout'，具体略git remote add origin git@github.com:yourname/yourrepo.git# 下载git pull origin master","categories":[{"name":"代码管理","slug":"代码管理","permalink":"https://liumengjun.github.io/categories/代码管理/"}],"tags":[{"name":"git","slug":"git","permalink":"https://liumengjun.github.io/tags/git/"}]},{"title":"Gradle 跨模块依赖测试代码","date":"2018-03-31T15:00:00.000Z","path":"2018/03/31/gradle-test-source-dependencies.html","text":"gradle中，模块\bA依赖core模块的测试代码测试代码(test文件夹下的代码)，是不跟随打包发布的，而且默认不随project依赖传递到\b其他的模块，需要用.sourceSets.test.output指明 简单配置，如下：123456// A's build.gradledependencies &#123; compile project(':core') //... testCompile project(':core').sourceSets.test.output&#125; 或者，configuration of testOutput以上只是简单的配置，也可以配置一个testOutput configuration，具体如下： 1234567// core's build.gradleconfigurations &#123; testOutput&#125;dependencies &#123; testOutput sourceSets.test.output&#125; 然后 12345// A's build.gradledependencies &#123; //... testCompile project(path: ':core', configuration: 'testOutput')&#125; 参考链接 Gradle: sub-project test dependencies in multi-project builds","categories":[{"name":"构建工具","slug":"构建工具","permalink":"https://liumengjun.github.io/categories/构建工具/"}],"tags":[{"name":"Gradle","slug":"Gradle","permalink":"https://liumengjun.github.io/tags/Gradle/"},{"name":"java","slug":"java","permalink":"https://liumengjun.github.io/tags/java/"}]},{"title":"关于 Gradle 执行 main-class","date":"2018-03-30T13:04:04.000Z","path":"2018/03/30/gradle-execute-main-class.html","text":"用application插件，或使用JavaExec任务 传递jvm option用jvmArgs属性，示例如下：12345678task execute(type:JavaExec) &#123; //only for projects do not have \"main\" classes but use default starters if(project.hasProperty('mainClassName')) &#123; main = mainClassName classpath = sourceSets.main.runtimeClasspath jvmArgs = [\"-agentlib:jdwp=transport=dt_socket,address=31843,suspend=n,server=y\", \"-Dgreeting=hello\"] &#125;&#125; 调试gradle启动的程序：GRADLE_OPTS环境变量只是把给定的参数传递给gradle，没有传递给要执行的main-class。比如要调试程序，用GRADLE_OPTS是没用的，我们不调试gradle，我们需要调试的是main-class，故需要用jvmArgs。 两个参考链接 (1) The Application Plugin - Gradle User Manual (2) Gradle to execute Java class (without modifying build.gradle) - Stack Overflow","categories":[{"name":"构建工具","slug":"构建工具","permalink":"https://liumengjun.github.io/categories/构建工具/"}],"tags":[{"name":"Gradle","slug":"Gradle","permalink":"https://liumengjun.github.io/tags/Gradle/"},{"name":"java","slug":"java","permalink":"https://liumengjun.github.io/tags/java/"}]},{"title":"标记语言文本学习","date":"2016-12-19T12:27:10.000Z","path":"2016/12/19/markup-text.html","text":"&nbsp;&nbsp;现在最流行的标记语言文本要数Markdown(*.md)了，其实它的出现是为了更方便的读写，然后转换为我们更熟知的HTML (HyperText Markup Language)。HTML就是一种标记语言，XML (eXtensible Markup Language)也是，它们都是MarkUP(标记上)，而Markdown是MarkDOWN(标记下)。&nbsp;&nbsp;为了便于读写、或者数据交换，人类已经造出了很多标记语言文本，简单学习几个，具体语法使用某度和某哥会给出来一堆；HTML和XML就不说了。 Markdown(*.md)&nbsp;&nbsp;应用于代码库的Readme.md文件，帮助文档等等各种场景。Markdown很简洁，特别易于读写，可以称得上是最轻量级的了。但是语法有些不统一，尤其各家工具处理缩进和换行时不一样。优点明显大于缺点，大家都在向GitHub GFM看齐吧。 reStructuredText(*.rst)&nbsp;&nbsp;Python文档使用较多，写个Readme.rst也是没问题的，GitHub也可以直接渲染rst成HTML预览。rst语法很规范，对比Markdown有些语法相似，稍微复杂一点点。Python Package的标准文档格式，起初还创建了一个工具Sphinx来处理Python文档。其实使用rst的也是大有人在。 RubyDoc(*.rdoc)&nbsp;&nbsp;Ruby项目的文档系统。*.rdoc也被各个代码托管平台直接像HTML那样展示。RDoc可以生成HTML，Ruby自带rdoc命令，而且可以像javadoc那样，生成整个项目的在线API文档。不过国人用Ruby的是不是少呀？ RedCloth(*.textile)&nbsp;&nbsp;textile也是Ruby系的标记语言文本。由RedCloth模块处理。它的语法同样很简洁，在各个平台上*.textile也可以直接以HTML预览。现在textile也被应用到了其他编程语言项目。不过这后缀名太长了。 YAML(*.yml)&nbsp;&nbsp;YAML(YAML Ain’t Markup Language)YAML不是标记语言，但是它以ML结尾所以列出来了学习一下。YAML生下来是作为一种所有编程语言友好的数据序列化标准的，也用于项目配置文件，如docker，swagger，hexo。顺便提一下JSON，JSON也用于数据序列化和配置文件。语法格式上YAML取决于代码块缩进，而JSON由’{‘,’}’来区分。 &nbsp;&nbsp;平时编程常用的就是上面这几个(虽然YAML不算，但也很常用)，还有其他的如SGML，VRML，WML，DocBook，LaTeX，OPML等等太多了。有些或已过时，有些正在制定标准，各种场景又有不同格式的标记文本… 工具Editor.md: Markdown在线编辑器Pandoc: 支持多种格式互转docutils: 把reStructuredText转换成其他格式RedCloth: 把textile转成htmlChrome、Atom、Idea、Sublime都有相应的插件。","categories":[{"name":"开源工具","slug":"开源工具","permalink":"https://liumengjun.github.io/categories/开源工具/"}],"tags":[{"name":"Markdown","slug":"Markdown","permalink":"https://liumengjun.github.io/tags/Markdown/"},{"name":"reStructuredText","slug":"reStructuredText","permalink":"https://liumengjun.github.io/tags/reStructuredText/"},{"name":"RDoc","slug":"RDoc","permalink":"https://liumengjun.github.io/tags/RDoc/"},{"name":"textile","slug":"textile","permalink":"https://liumengjun.github.io/tags/textile/"},{"name":"YAML","slug":"YAML","permalink":"https://liumengjun.github.io/tags/YAML/"}]},{"title":"Hello Hexo","date":"2016-12-15T12:46:25.000Z","path":"2016/12/15/hello-hexo.html","text":"计划搭建个人博客，用了下面提到的框架，这是自动生成的文章 (尊重原创，没有删除，不是广告哟) Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[{"name":"网页搭建","slug":"网页搭建","permalink":"https://liumengjun.github.io/categories/网页搭建/"}],"tags":[{"name":"Blog","slug":"Blog","permalink":"https://liumengjun.github.io/tags/Blog/"},{"name":"WEB","slug":"WEB","permalink":"https://liumengjun.github.io/tags/WEB/"}]},{"title":"一些github使用技巧","date":"2016-11-15T12:46:25.000Z","path":"2016/11/15/tricks-gh.html","text":"预览html https://htmlpreview.github.io/ raw文件 raw.githubusercontent.come.g. https://raw.githubusercontent.com/liumengjun/towersOfHanoi/master/towersOfHanoi.apk ?raw=truee.g. https://github.com/liumengjun/SudokuPuzzle/blob/master/SudokuPuzzle.apk?raw=true 打包下载归档链接 github.com/repos/:owner/:repo/:archive_format/:ref @see GitHub API 字段 说明 owner GitHub用户名 repo 项目名 archive_format tarball 或 zipball ref 有效的Git引用，branch、tag、commit 例如：https://github.com/liumengjun/liumengjun.github.io/tarball/masterhttps://github.com/liumengjun/liumengjun.github.io/zipball/b16ffbcb8 删除敏感数据 use bfg or git-filter-branch. @see help doc git-rebase -i 修改历史commit点然后提交（commit较多时不方便） GitHub Pages create a repo named ${your_username}.github.io. more&gt;&gt;","categories":[{"name":"开源工具","slug":"开源工具","permalink":"https://liumengjun.github.io/categories/开源工具/"}],"tags":[{"name":"git","slug":"git","permalink":"https://liumengjun.github.io/tags/git/"},{"name":"github","slug":"github","permalink":"https://liumengjun.github.io/tags/github/"}]}]